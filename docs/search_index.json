[
["index.html", "Bookdown Example Preface", " Bookdown Example 481 Student 2020-09-28 Preface This is an example of using bookdown. When you first clone a repo from it as a template, the docs folder only includes this preface (from index.Rmd). That’s because I built the book to initially only include this preface (so that’s all you’ll see in GitHub Pages as well). You’ll see that in the main project folder there are two additional RMD files, “01-RegressionOutputTables.Rmd” and “02-LeafletMap.Rmd”. When you build the book, the output for these two files will be included as two chapters. This demonstrates that you were able to build the book successfully. A quick note about these two chapters: THese two chapters are two RMD files from Econ 380. The first has examples of displaying regression output and graphs. The second has an interactive map. These files demonstrate two ways of reading in data. In the first chapter, data is read in from a CSV file (“ceo.csv”). We will always put data into a folder named “data” that we place in the main project folder. This means we always use data/filename to read in the data, for example, read.csv(\"data/ceo.csv\"). Then we can include “data” in the “.gitignore” file so that Git ignores it. Some of the data files will be really large. This allows us to avoid pushing and pulling the data from GitHub. It makes everything in RStudio much quicker because Git doesn’t have to examine large data files to determine if they’ve changed. And some of the data files might be too large to store in GitHub even if we didn’t mind waiting. Following this convention means you have to manually create the data folder and put the data files in that folder. For the data I give you, I’ll post it in Moodle in a Zip folder. In the second RMD file (with the map), data is read in directly from a URL. We will always use this basic setup. ALways open RStudio by opening the .RProj folder so that the working directory is set correctly. Always put a “data” folder in the main project folder and open data using “data/filename”, for example, read.csv(\"data/ceo.csv\"). "],
["regression-output-table-examples.html", "1 Regression Output Table Examples 1.1 Summary Statistics 1.2 Model comparisons 1.3 Test Linear Combinations of Parameters 1.4 Log transformations", " 1 Regression Output Table Examples #I AM MAKING A CHANGE-YILDIZ ALTIN! This RMD file was one of the examples you worked through in 380. I’m including it in this example for a few reasons. First, you can see how RMD files that you used before as standalone RMD files to create standalone HTML output can be combined in a book using bookdown. Second, this file loads data using read.csv(\"data/ceo.csv\"), serving as an example of how you will store all data in a “data” folder put in the main project folder. Third, this file provides examples of showing regression output side by side. Note: Generally it’s a good idea to load your packages in a code chunk at the top rather than mixed in with the rest of the document. However, for this example I am going to load the packages in the same code chunk where I use them so that you can see exactly what package is needed for specific functions. The dataset ceo.csv has the following variables: Variable Description salary 1990 compensation in dollars ($) age age of CEO in years comten years CEO with company ceoten years as ceo with company sales 1990 firm sales in $millions profits 1990 profits in $millions mktval 1990 market value in $millions 1.1 Summary Statistics The stargazer package provides an easy way to display summary statistics. You need the result='asis' codechunk option so that it displays the html table in the knit output file. The warning=FALSE and message=FALSE keeps it from displaying some of the messages it displays by default. One limitation of the table output is that it doesn’t leave much space horizontally. This can be controlled by HTML options for cell padding in tables. library(stargazer) mydata &lt;- read.csv(&quot;data/ceo.csv&quot;) stargazer(mydata, type = &quot;html&quot;,summary.stat = c(&quot;n&quot;,&quot;mean&quot;,&quot;sd&quot;, &quot;min&quot;, &quot;median&quot;, &quot;max&quot;)) Statistic N Mean St. Dev. Min Median Max salary 177 865,864.400 587,589.300 100,000 707,000 5,299,000 age 177 56.429 8.422 33 57 86 comten 177 22.503 12.295 2 23 58 ceoten 177 7.955 7.151 0 6 37 sales 177 3,529.463 6,088.654 29 1,400 51,300 profits 177 207.831 404.454 -463 63 2,700 mktval 177 3,600.316 6,442.276 387 1,200 45,400 1.2 Model comparisons Consider four models: model1 &lt;- lm(salary~sales+mktval+profits,data=mydata) model2 &lt;- lm(salary~sales+mktval+profits+age,data=mydata) model3 &lt;- lm(salary~sales+mktval+profits+ceoten,data=mydata) model4 &lt;- lm(salary~sales+mktval+profits+ceoten+age,data=mydata) One package that allows you to report the results for all four models is the stargazer package. This produces a table similar to the esttab output in Stata. Remember that each column is a separate model and if a variable does not have a coefficient displayed in a column, that means it was not included as an explanatory variable in that model. stargazer(model1, model2, model3, model4, type = &quot;html&quot;, report=(&#39;vc*p&#39;)) Dependent variable: salary (1) (2) (3) (4) sales 15.984 15.369 18.233* 18.061 p = 0.152 p = 0.169 p = 0.100 p = 0.106 mktval 23.831 23.842 21.157 21.231 p = 0.137 p = 0.137 p = 0.183 p = 0.183 profits 31.703 28.100 48.636 47.528 p = 0.909 p = 0.920 p = 0.859 p = 0.863 age 4,528.026 823.966 p = 0.353 p = 0.873 ceoten 12,730.860** 12,390.430** p = 0.026 p = 0.042 Constant 717,062.400*** 464,424.700* 613,958.800*** 570,743.300** p = 0.000 p = 0.093 p = 0.000 p = 0.042 Observations 177 177 177 177 R2 0.178 0.182 0.201 0.202 Adjusted R2 0.163 0.163 0.183 0.178 Residual Std. Error 537,420.300 (df = 173) 537,621.100 (df = 172) 531,159.300 (df = 172) 532,670.100 (df = 171) F Statistic 12.464*** (df = 3; 173) 9.559*** (df = 4; 172) 10.846*** (df = 4; 172) 8.633*** (df = 5; 171) Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 1.2.1 Adjusted R-Squared Recall the definition of \\(R^2\\): \\[ R^2 = \\frac{SSE}{SST} = 1 - \\frac{SSR}{SST} \\] The denominator measures the total variation in the \\(y\\) variable: \\(SST = (n-1)Var(y)\\). Thus, it has nothing to do with the explanatory variables. Adding additional \\(x\\) variables does not affect \\(SST\\). Adding an additional \\(x\\) variable cannot decrease how much of the variation in \\(y\\) explained by the model, so \\(SSE\\) will not decrease. Usually it increases at least a little bit. Thus, adding an additional \\(x\\) variable cannot decrease \\(R^2\\), and it usually increases it at least a little bit. This means that \\(R^2\\) increasing is a not a good justification for adding an additional \\(x\\) variable to the model. Adjusted \\(R^2\\), often denoted \\(\\bar{R}^2\\), penalizes you for adding an additional \\(x\\) variable. Adjusted \\(R^2\\) only increases if the new variable has a sufficiently significant effect on \\(y\\). Adjusted \\(R^2\\) is defined as \\[ \\bar{R}^2 = 1 - \\frac{\\left(\\frac{SSR}{n-k-1}\\right)}{\\left(\\frac{SST}{n-1}\\right)} \\] Look at the models above. All four models include measures of the company, including sales, market value, and profits. Models 2-4 add variables measuring characteristics of the CEO. Compare models 1 and 2. Adding the CEOs age increases \\(R^2\\) but adjusted \\(R^2\\) does not increase, indicating that adding age does not improve the model. Comparing models 1 and 3, both \\(R^2\\) and adjusted \\(R^2\\) increase when adding the CEO’s tenure, indicating this variable does improve the model. Comparing models 3 and 4, we again see that adding the CEO’s age does not improve the model; \\(R^2\\) increases slightly but adjusted \\(R^2\\) goes down. 1.3 Test Linear Combinations of Parameters Consider again Model 3. I’ll display the estimates again here to demonstrate using the kable() from knitr and broom) library(knitr) library(broom) model3 &lt;- lm(salary~sales+mktval+profits+ceoten,data=mydata) kable(tidy(model3),digits = 2) term estimate std.error statistic p.value (Intercept) 613958.78 65486.13 9.38 0.00 sales 18.23 11.01 1.66 0.10 mktval 21.16 15.79 1.34 0.18 profits 48.64 273.37 0.18 0.86 ceoten 12730.86 5635.96 2.26 0.03 It looks like the coefficient on profits (48.636087) is larger than the coefficient on sales, but is this difference statistically significant? The test statistic is \\[ t=\\frac{\\left(\\hat{\\beta}_{profit}-\\hat{\\beta}_{sales}\\right)-0}{se\\left(\\hat{\\beta}_{profit}-\\hat{\\beta}_{sales}\\right)} \\] In R, this test can be implemented using the glht() function from the multcomp package: library(multcomp) ##We need to know the &quot;names&quot; so we can reference them names(coef(model3)) ## [1] &quot;(Intercept)&quot; &quot;sales&quot; &quot;mktval&quot; &quot;profits&quot; &quot;ceoten&quot; testOfDif &lt;- glht(model3, linfct = c(&quot;profits - sales = 0&quot;)) summary(testOfDif) ## ## Simultaneous Tests for General Linear Hypotheses ## ## Fit: lm(formula = salary ~ sales + mktval + profits + ceoten, data = mydata) ## ## Linear Hypotheses: ## Estimate Std. Error t value Pr(&gt;|t|) ## profits - sales == 0 30.4 278.0 0.109 0.913 ## (Adjusted p values reported -- single-step method) confint(testOfDif) ## ## Simultaneous Confidence Intervals ## ## Fit: lm(formula = salary ~ sales + mktval + profits + ceoten, data = mydata) ## ## Quantile = 1.9739 ## 95% family-wise confidence level ## ## ## Linear Hypotheses: ## Estimate lwr upr ## profits - sales == 0 30.4026 -518.2618 579.0671 What about ceoten compared to sales? testOfDif2 &lt;- glht(model3, linfct = c(&quot;ceoten - sales = 0&quot;)) summary(testOfDif2) ## ## Simultaneous Tests for General Linear Hypotheses ## ## Fit: lm(formula = salary ~ sales + mktval + profits + ceoten, data = mydata) ## ## Linear Hypotheses: ## Estimate Std. Error t value Pr(&gt;|t|) ## ceoten - sales == 0 12713 5635 2.256 0.0253 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## (Adjusted p values reported -- single-step method) confint(testOfDif2) ## ## Simultaneous Confidence Intervals ## ## Fit: lm(formula = salary ~ sales + mktval + profits + ceoten, data = mydata) ## ## Quantile = 1.9739 ## 95% family-wise confidence level ## ## ## Linear Hypotheses: ## Estimate lwr upr ## ceoten - sales == 0 12712.6292 1590.0204 23835.2380 1.4 Log transformations This data provides a good example of why visualizing the data can be helpful. By looking at histograms and scatter plots, you can see the effects of log transformations. . 1.4.1 Histograms Try making histograms of salary and log(salary) Try making histograms of sales and log(sales) First, here is a histogram of sales. library(ggplot2) ggplot(mydata,aes(x=sales)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. library(ggplot2) ggplot(mydata,aes(x=sales)) + geom_histogram(fill=&quot;skyblue&quot;, color=&quot;black&quot;) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. This distribution is very skewed. Here is the histogram of \\(log(sales)\\) mydata$logsales &lt;- log(mydata$sales) ggplot(mydata,aes(x=logsales)) + geom_histogram(fill=&quot;skyblue&quot;, color=&quot;black&quot;) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. We notice a similar pattern with salary. ggplot(mydata,aes(x=sales)) + geom_histogram(fill=&quot;skyblue&quot;, color=&quot;black&quot;) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. mydata$logsalary &lt;- log(mydata$salary) ggplot(mydata,aes(x=logsales)) + geom_histogram(fill=&quot;skyblue&quot;, color=&quot;black&quot;) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 1.4.2 Scatter plots You can also see how log transformations spreads out the data by looking at scatter plots of salary or log(salary) (y) versus sales or log(sales) corresponding with the four different models. I colored the points based on age just as an example. That has nothing to do with the log transformations. ##plot(mydata$salary,mydata$sales) ggplot(mydata,aes(y=salary,x=sales,col=age))+geom_point()+ scale_colour_gradientn(colours=rainbow(3)) + geom_smooth(method=&#39;lm&#39;,se=FALSE,col=&#39;black&#39;) ## `geom_smooth()` using formula &#39;y ~ x&#39; ##plot(mydata$salary,mydata$sales) ggplot(mydata,aes(y=salary,x=logsales,col=age))+geom_point()+ scale_colour_gradientn(colours=rainbow(3)) + geom_smooth(method=&#39;lm&#39;,se=FALSE,col=&#39;black&#39;) ## `geom_smooth()` using formula &#39;y ~ x&#39; ##plot(mydata$salary,mydata$sales) ggplot(mydata,aes(y=logsalary,x=sales,col=age))+geom_point()+ scale_colour_gradientn(colours=rainbow(3))+ geom_smooth(method=&#39;lm&#39;,se=FALSE,col=&#39;black&#39;) ## `geom_smooth()` using formula &#39;y ~ x&#39; ##plot(mydata$salary,mydata$sales) ggplot(mydata,aes(y=logsalary,x=logsales,col=age))+geom_point()+ scale_colour_gradientn(colours=rainbow(3)) + geom_smooth(method=&#39;lm&#39;,se=FALSE,col=&#39;black&#39;) ## `geom_smooth()` using formula &#39;y ~ x&#39; mydata$logsalary &lt;- log(mydata$salary) model4 &lt;- lm(salary~sales+mktval+profits+ceoten+age,data=mydata) model4loglevel &lt;- lm(logsalary~sales+mktval+profits+ceoten+age,data=mydata) model4levellog &lt;- lm(salary~logsales+mktval+profits+ceoten+age,data=mydata) model4loglog &lt;- lm(logsalary~logsales+mktval+profits+ceoten+age,data=mydata) stargazer(model4, model4loglevel, model4levellog, model4loglog, type = &quot;html&quot;, report=(&#39;vc*p&#39;)) Dependent variable: salary logsalary salary logsalary (1) (2) (3) (4) sales 18.061 0.00003** p = 0.106 p = 0.022 logsales 126,644.400*** 0.200*** p = 0.0004 p = 0.00000 mktval 21.231 0.00002 19.547 0.00001 p = 0.183 p = 0.280 p = 0.205 p = 0.330 profits 47.528 0.00002 23.633 -0.00003 p = 0.863 p = 0.932 p = 0.925 p = 0.894 ceoten 12,390.430** 0.011* 13,284.340** 0.013** p = 0.042 p = 0.066 p = 0.025 p = 0.025 age 823.966 -0.001 -1,679.167 -0.005 p = 0.873 p = 0.880 p = 0.740 p = 0.332 Constant 570,743.300** 13.282*** -136,111.300 12.171*** p = 0.042 p = 0.000 p = 0.680 p = 0.000 Observations 177 177 177 177 R2 0.202 0.206 0.247 0.316 Adjusted R2 0.178 0.182 0.225 0.296 Residual Std. Error (df = 171) 532,670.100 0.548 517,256.700 0.509 F Statistic (df = 5; 171) 8.633*** 8.853*** 11.223*** 15.789*** Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 mydata$logsalary = log(mydata$salary) model0 &lt;- lm(salary~sales,data=mydata) model0loglevel &lt;- lm(logsalary~sales,data=mydata) model0levellog &lt;- lm(salary~logsales,data=mydata) model0loglog &lt;- lm(logsalary~logsales,data=mydata) stargazer(model0, model0loglevel, model0levellog, model0loglog, type = &quot;html&quot;, report=(&#39;vc*p&#39;)) Dependent variable: salary logsalary salary logsalary (1) (2) (3) (4) sales 36.694*** 0.00004*** p = 0.00000 p = 0.000 logsales 177,149.100*** 0.224*** p = 0.000 p = 0.000 Constant 736,355.200*** 13.347*** -415,105.000** 11.869*** p = 0.000 p = 0.000 p = 0.046 p = 0.000 Observations 177 177 177 177 R2 0.145 0.168 0.186 0.281 Adjusted R2 0.140 0.163 0.182 0.277 Residual Std. Error (df = 175) 545,008.600 0.554 531,513.300 0.515 F Statistic (df = 1; 175) 29.576*** 35.327*** 40.096*** 68.345*** Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 "],
["interactive-choropleth-map.html", "2 Interactive Choropleth Map 2.1 Shapefiles 2.2 Data 2.3 Maps 2.4 Map 1: Quantiles with diverging Red-Blue Scale", " 2 Interactive Choropleth Map This chapter has an example of creating an interactive leaflet map using 2016 county-level election results. I left it mostly unchanged from what you did in 380 so you’ll recognize it and can see how bookdown uses RMD files you’ve used in the past and just puts them together as a book. library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union library(leaflet) library(tigris) ## To enable ## caching of data, set `options(tigris_use_cache = TRUE)` in your R script or .Rprofile. options(tigris_use_cache = TRUE) This assignment builds on what you did in HW-02-12 and what we discussed in class Tuesday (Feb. 12). 2.1 Shapefiles You can use the same packages and GIS shapefiles as you did in HW-02-12. #load GIS shapefiles using tigris package functions statesGIS &lt;- states(cb = TRUE,resolution = &quot;20m&quot;) countiesGIS &lt;- counties(cb = TRUE,resolution = &quot;20m&quot;) ## Drop Puerto Rico (since we don&#39;t have election data for it) countiesGIS &lt;- subset(countiesGIS,STATEFP != &quot;72&quot;) statesGIS &lt;- subset(statesGIS,STATEFP != &quot;72&quot;) ## Let&#39;s also drop Alaska and Hawaii countiesGIS &lt;- subset(countiesGIS,!(STATEFP %in% c(&quot;02&quot;,&quot;15&quot;))) statesGIS &lt;- subset(statesGIS,!(STATEFP %in% c(&quot;02&quot;,&quot;15&quot;))) ## Keep only the columns we need (GEOID is 5-character FIPS) ## This part isn&#39;t necessary. It just makes the resulting file a little smaller, so the final map will load a little quicker. I won&#39;t bother for statesGIS because it&#39;s small already countiesGIS &lt;- countiesGIS[,(names(countiesGIS) %in% c(&quot;GEOID&quot;,&quot;NAME&quot;))] 2.2 Data For this assignment you can use data for the 2016 presidential election. The website we used for the 2004, 2008, and 2012 election results for HW-02-12 linked to a github page with data for the 2016 election. The site has Python code to scrape the data from a website (which we’re not going to look at but some of you might find interesting at some point). We’ll use the csv file they named 2016_US_County_Level_Presidential_Results.csv. When you click on the link to that file you see it displayed in GitHub. If you click on the “Raw” button near the top of the data it opens up the actual csv file, i.e., a page with values separated by commas. Copy the URL of this page. Paste the URL as the file name in the read.csv() function. Then manipulate the data so that it can be used to make the maps. Make sure to fix the FIPS code for Oglala Lakota, SD by changing FIPS code 46113 in the 2016 voting data to FIPS code 46102 before merging with the county shape file (countiesGIS). To make sure you understand how this works, here is an example using the 2012 data from HW-02-12. The URL for that data is (http://faculty.baruch.cuny.edu/geoportal/data/county_election/elpo12p010g.csv). You could read this data using the command dta2012 &lt;- read.csv(\"http://faculty.baruch.cuny.edu/geoportal/data/county_election/elpo12p010g.csv\") instead of downloading the file. ## Read the data from URL # dta2016 &lt;- read.csv(&quot;put URL here&quot;) # Write rest of code to manipulate data and merge it with countiesGIS ## Read the data from URL dta2016 &lt;- read.csv(&quot;https://raw.githubusercontent.com/tonmcg/US_County_Level_Election_Results_08-16/master/2016_US_County_Level_Presidential_Results.csv&quot;) ## Remember to examine the column names colnames(dta2016) ## [1] &quot;X&quot; &quot;votes_dem&quot; &quot;votes_gop&quot; &quot;total_votes&quot; ## [5] &quot;per_dem&quot; &quot;per_gop&quot; &quot;diff&quot; &quot;per_point_diff&quot; ## [9] &quot;state_abbr&quot; &quot;county_name&quot; &quot;combined_fips&quot; dta2016$Winner2016 &lt;- ifelse(dta2016$votes_gop &gt; dta2016$votes_dem,&quot;Trump&quot;,&quot;Clinton&quot;) colnames(dta2016)[colnames(dta2016)==&quot;combined_fips&quot;] &lt;- &quot;FIPS&quot; colnames(dta2016)[colnames(dta2016)==&quot;state_abbr&quot;] &lt;- &quot;STATE&quot; colnames(dta2016)[colnames(dta2016)==&quot;per_dem&quot;] &lt;- &quot;PctDem2016&quot; colnames(dta2016)[colnames(dta2016)==&quot;per_gop&quot;] &lt;- &quot;PctRep2016&quot; colnames(dta2016)[colnames(dta2016)==&quot;total_votes&quot;] &lt;- &quot;TotalVote2016&quot; dta2016$PctWinner2016 &lt;- pmax(dta2016$PctDem2016,dta2016$PctRep2016) dta2016$FontColorWinner2016 &lt;- ifelse(dta2016$votes_gop &gt; dta2016$votes_dem,&quot;red&quot;, ifelse(dta2016$votes_gop &lt; dta2016$votes_dem,&quot;blue&quot;, &quot;purple&quot;)) dta2016[dta2016$FIPS==46113,] ## X votes_dem votes_gop TotalVote2016 PctDem2016 PctRep2016 diff ## 2412 2411 2504 241 2896 0.8646409 0.08321823 2,263 ## per_point_diff STATE county_name FIPS Winner2016 PctWinner2016 ## 2412 78.14% SD Oglala County 46113 Clinton 0.8646409 ## FontColorWinner2016 ## 2412 blue dta2016[dta2016$FIPS==46102,] ## [1] X votes_dem votes_gop ## [4] TotalVote2016 PctDem2016 PctRep2016 ## [7] diff per_point_diff STATE ## [10] county_name FIPS Winner2016 ## [13] PctWinner2016 FontColorWinner2016 ## &lt;0 rows&gt; (or 0-length row.names) dta2016$FIPS &lt;- ifelse(dta2016$FIPS==46113,46102,dta2016$FIPS) dta2016[dta2016$FIPS==46113,] ## [1] X votes_dem votes_gop ## [4] TotalVote2016 PctDem2016 PctRep2016 ## [7] diff per_point_diff STATE ## [10] county_name FIPS Winner2016 ## [13] PctWinner2016 FontColorWinner2016 ## &lt;0 rows&gt; (or 0-length row.names) dta2016[dta2016$FIPS==46102,] ## X votes_dem votes_gop TotalVote2016 PctDem2016 PctRep2016 diff ## 2412 2411 2504 241 2896 0.8646409 0.08321823 2,263 ## per_point_diff STATE county_name FIPS Winner2016 PctWinner2016 ## 2412 78.14% SD Oglala County 46102 Clinton 0.8646409 ## FontColorWinner2016 ## 2412 blue dtaAllYears &lt;- select(dta2016,&quot;FIPS&quot;,&quot;STATE&quot;,&quot;PctDem2016&quot;, &quot;PctRep2016&quot;,&quot;PctWinner2016&quot;,&quot;TotalVote2016&quot;, &quot;Winner2016&quot;,&quot;FontColorWinner2016&quot;) #Create GEOID string from int FIPS dtaAllYears$GEOID &lt;- sprintf(&quot;%05d&quot;, dtaAllYears$FIPS) ## Merge mydata with shapefile data county_dta &lt;- geo_join(countiesGIS, dtaAllYears,&quot;GEOID&quot;,&quot;GEOID&quot;) ## Warning: `group_by_()` is deprecated as of dplyr 0.7.0. ## Please use `group_by()` instead. ## See vignette(&#39;programming&#39;) for more help ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_warnings()` to see where this warning was generated. ## MODIFY/ADD TO THIS CODE to include 2004 just like 2008 and 2012: popup_dta &lt;- paste0(&quot;&lt;strong&gt;&quot;,county_dta$NAME ,&quot;, &quot;,county_dta$STATE,&quot; (&quot;,county_dta$GEOID,&quot;)&lt;/strong&gt;&quot;, &quot;&lt;br&gt;&lt;font color=&#39;&quot;,county_dta$FontColorWinner2012,&quot;&#39;&gt;2012: &quot;, format(county_dta$Winner2016,big.mark=&quot;,&quot;, trim=TRUE), &quot; (&quot;, format(county_dta$PctWinner2016,digits=3, trim=TRUE), &quot;%)&lt;/font&gt;&quot; ) labels &lt;- popup_dta %&gt;% lapply(htmltools::HTML) 2.3 Maps Each map should be what we called “Popup on mouseover” map in HW-02-12 (i.e. one layer with a popup that opens without the need to click). Each map should be a… choropleth map of Percent Voting for the Democrat in 2016 (e.g., PctDem2016) with a… popup displaying County name, ST (e.g., “Outagamie, WI”), the name of the winner (Trump or Clinton), and the percent voting for the winner. The only difference between the maps should be the color function (and the legend and legend label).Make one map per code chunk below. Each code chunk should have the following: Color palette function (i.e., pal &lt;- ...). Before this function we’ll include a line pal &lt;- NULL to make sure the previous palette isn’t being re-used. Variable with the legend title Code to make the map 2.4 Map 1: Quantiles with diverging Red-Blue Scale This map is identical to HW-02-12 so I’ll copy/paste the code for you. It uses the “RdBu” palette. Technically this is called a “diverging palette”. See this website for details about RColorBrewer: https://moderndata.plot.ly/create-colorful-graphs-in-r-with-rcolorbrewer-and-plotly/ #Make Color Palette pal &lt;- NULL pal &lt;- colorQuantile(&quot;RdBu&quot;, NULL, n = 9) #Legend title sLegendTitle &lt;- &quot;Percentiles: % Vote for Dem&quot; ## Map with state borders and popup if click leaflet(data= county_dta) %&gt;% addTiles() %&gt;% setView(-97, 39, zoom = 4) %&gt;% addPolygons( fillColor = ~pal(county_dta$PctDem2016), weight = 1, opacity = 1, color = &quot;white&quot;, dashArray = &quot;3&quot;, fillOpacity = 0.7, highlight = highlightOptions( weight = 5, color = &quot;#666&quot;, dashArray = &quot;&quot;, fillOpacity = 0.7, bringToFront = TRUE), label = labels, labelOptions = labelOptions( style = list(&quot;font-weight&quot; = &quot;normal&quot;, padding = &quot;3px 8px&quot;), textsize = &quot;15px&quot;, direction = &quot;auto&quot;)) %&gt;% addPolygons(data = statesGIS,fill = FALSE,color=&quot;yellow&quot;,weight = 1) %&gt;% addLegend(pal = pal,values = ~county_dta$PctDem2016, opacity = 0.7, title = sLegendTitle,position = &quot;bottomright&quot;) ## Warning: sf layer has inconsistent datum (+proj=longlat +datum=NAD83 +no_defs). ## Need &#39;+proj=longlat +datum=WGS84&#39; ## Warning: sf layer has inconsistent datum (+proj=longlat +datum=NAD83 +no_defs). ## Need &#39;+proj=longlat +datum=WGS84&#39; "]
]
